\documentclass[a4paper, 11pt,reqno]{article}
\input{/Users/olivierglorieux/Desktop/BCPST/2020:2021/preambule.tex}
\newif\ifshow
\showtrue
\input{/Users/olivierglorieux/Desktop/BCPST/2021:2022/ifshow.tex}

%\geometry{hmargin=2.0cm, vmargin=2cm}

\author{Olivier Glorieux}
\begin{document}
\title{DM 13 VAR }


\begin{exercice}%https://math1a.bcpsthoche.fr/docs/DS_1617.pdf
Pour toute variable aléatoire $X$ telle que l'ensemble de ses valeurs images $X(\Omega)$ est un sous-ensemble fini de $\mathbb{N}$, on définit sa fonction génératrice par :
$$g_{X}: t \mapsto \mathrm{E}\left(t^{X}\right) $$ où $\mathrm{E}$ désigne l'espérance.\\
Soit $X$ une telle variable aléatoire. On note $m \in \mathbb{N}$ sa valeur image maximale, ainsi $X(\Omega) \subset\{0,1,2, \ldots, m\}$.

\begin{enumerate}
  \item Justifier que $g_{X}$ est une fonction polynomiale.
  \item 
 \begin{enumerate}
\item   Calculer $g_{X}(1)$.
\item Montrer que $g_{X}^{\prime}(1)=\mathrm{E}(X)$.
\item  Montrer que $g_{X}^{\prime \prime}(1)=\mathrm{E}(X(X-1))$.
\item  Exprimer $\mathrm{V}(X)$ (où $\mathrm{V}$ désigne la variance) en fonction de $g_{X}^{\prime}(1)$ et $g_{X}^{\prime \prime}(1)$. 
\end{enumerate}  

  \item
  
 \begin{enumerate}
  \item  Exprimer $g_{X+1}$ à l'aide de $g_{X}$.
\item  Exprimer $g_{2 X}$ à l'aide de $g_{X}$.
\end{enumerate}  
  \item Dans cette question, on suppose que $X \hookrightarrow \mathcal{B}(n, p)$ où $(n, p) \in \mathbb{N} \times[0,1]$.
  
  \begin{enumerate}
\item  Calculer $g_{X}$.
\item  Retrouver les valeurs de $\mathrm{E}(X)$ et $\mathrm{V}(X)$ à l'aide de la fonction   génératrice.
  \end{enumerate}

\end{enumerate}
\end{exercice}

\begin{correction}

\begin{enumerate}
\item 
\begin{itemize}
  \item On a d'après le théorème de transfert:
\end{itemize}
$$
g_{X}: t \mapsto \mathrm{E}\left(t^{X}\right)=\sum_{k=0}^{m} t^{k} \mathrm{P}(X=k)=\sum_{k=0}^{m} a_{k} t^{k} 
$$
 en posant  $a_{k}=\mathrm{P}(X=k)$
\conclusion{Donc $g$ est bien une fonction polynomiale associée au polynôme $\ddp \sum_{k=0}^{m} a_{k} X^{k} \in \mathbb{R}[X]$.}

\item \begin{enumerate}

  \item Par définition de $g_{X}$, on a $g_{X}(1)=\mathrm{E}\left(1^{X}\right)=\mathrm{E}(1)=1$.
  \begin{align*}
g_{X}(1)&=\mathrm{E}\left(1^{X}\right)\\
&=\sum_{k=0}^{m} 1^{k} \mathrm{P}(X=k)\\
&=\sum_{k=0}^{m} \mathrm{P}(X=k)\\
&=\mathrm{P}\left(\bigcup_{k=0}^{m}(X=k)\right)\\
&=\mathrm{P}\left(X \in \bigcup_{k=0}^{m}\{k\}\right)\\
&=\mathrm{P}(X \in\{0,1,2, \ldots, m\})=1
  \end{align*}
\conclusion{$g_{X}(1)= 1$}

\item 
 La fonction génératrice $g_{X}$ est dérivable sur $\mathbb{R}$ car c'est une fonction polynomiale d'après la question 1. On a d'après le théorème de transfert :

$$
g_{X}: t \mapsto \mathrm{E}\left(t^{X}\right)=\sum_{k=0}^{m} t^{k} \mathrm{P}(X=k) $$
\text { donc }: $ g_{X}^{\prime}: t \mapsto \sum_{k=0}^{m} k t^{k-1} \mathrm{P}(X=k)
$
et en particulier :
$$
g_{X}^{\prime}(1)=\sum_{k=0}^{m} k 1^{k-1} \mathrm{P}(X=k)=\sum_{k=0}^{m} k \mathrm{P}(X=k)=\mathrm{E}(X)
$$
\conclusion{$g_{X}^{\prime}(1)=\mathrm{E}(X)$}


\item  La fonction génératrice est deux fois dérivable sur $\mathbb{R}$ pour les mêmes raisons que celles exposées à la question précédente, et on a :
$$
g_{X}^{\prime \prime}: t \mapsto \sum_{k=0}^{m} k(k-1) t^{k-2} \mathrm{P}(X=k)
$$
donc en particulier :
$$
g_{X}^{\prime \prime}(1)=\sum_{k=0}^{m} k(k-1) 1^{k-2} \mathrm{P}(X=k)=\sum_{k=0}^{m} k(k-1) \mathrm{P}(X=k)=\mathrm{E}(X(X-1))
$$
d'après le théorème de transfert.
\conclusion{$g_{X}^{\prime \prime}(1)=\mathrm{E}(X(X-1))$}
\item  On a d'après la formule de Koenig-Huygens :

$$
\mathrm{V}(X)=\mathrm{E}\left((X-\mathrm{E}(X))^{2}\right)=\mathrm{E}\left(X^{2}\right)-\mathrm{E}(X)^{2}
$$
Or on a par linéarité de l'espérance :
$$
\mathrm{E}(X(X-1))=\mathrm{E}\left(X^{2}-X\right)=\mathrm{E}\left(X^{2}\right)-\mathrm{E}(X)
$$
 On peut également justifier cette égalité en détaillant les calculs à l'aide du  théorème de transfert et la linéarité de la somme.  D'où en utilisant les résultats des questions précédentes :
 \begin{align*}
\mathrm{V}(X) &=\mathrm{E}\left(X^{2}\right)-\mathrm{E}(X)^{2}\\
					&=\mathrm{E}\left(X^{2}\right)-\mathrm{E}(X)+\mathrm{E}(X)-\mathrm{E}(X)^{2}\\
					&=\mathrm{E}(X(X-1))+\mathrm{E}(X)(1-\mathrm{E}(X)) \\
					&= g_{X}^{\prime \prime}(1)+g_{X}^{\prime}(1)\left(1-g_{X}^{\prime}(1)\right) .
\end{align*}  

\conclusion{$\mathrm{V}(X) =g_{X}^{\prime \prime}(1)+g_{X}^{\prime}(1)\left(1-g_{X}^{\prime}(1)\right) .$}

\end{enumerate}
\item
\begin{enumerate}
\item $g_{X+1}: t \mapsto \mathrm{E}\left(t^{X+1}\right)=\mathrm{E}\left(t^{X} \times t\right)=\mathrm{E}\left(t^{X}\right) \times t=t g_{X}(t) \quad$ par linéarité de l'espérance.

\conclusion{ $g_{X+1}(t) = tg_X(t)$}

\item Par définition de la fonction génatrice, on a:
$$
g_{2 X}: t \mapsto \mathrm{E}\left(t^{2 X}\right)=\mathrm{E}\left(\left(t^{2}\right)^{X}\right)=g_{X}\left(t^{2}\right)
$$
\conclusion{$g_{2 X}(t)=g_{X}\left(t^{2}\right)$}
\end{enumerate}
\item \begin{enumerate}
\item $$
X(\Omega)=\{0,1,2, \ldots, n\} \quad \text { et } \quad \forall k \in X(\Omega), P(X=k)=\left(\begin{array}{l}
n \\
k
\end{array}\right) p^{k}(1-p)^{n-k}
$$
On en déduit d'après le théorème de transfert que :
\begin{align*}
g_{X}( t)&=\mathrm{E}\left(t^{X}\right)&\\
	&=\sum_{k=0}^{n} t^{k} \mathrm{P}(X=k)\\
	&=\sum_{k=0}^{n} t^{k}\binom{n}{k}p^{k}(1-p)^{n-k}\\
&=\sum_{k=0}^{n}\binom{n}{k}(p t)^{k}(1-p)^{n-k}
\end{align*}

Puis,  en utilisant la formule du binôme de Newton :
\conclusion{
$g_{X}( t)=(p t+1-p)^{n}
$}
\item On a d'après le résultat de la question précédente :
$$
g_{X}^{\prime}: t \mapsto n p(p t+1-p)^{n-1} \text { et } g_{X}^{\prime \prime}: t \mapsto n(n-1) p^{2}(p t+1-p)^{n-2} .
$$
On en déduit d'après les résultat de la question 2 que :
$$
\begin{aligned}
\mathrm{E}(X) &=g_{X}^{\prime}(1)=n p(p+1-p)^{n-1}=n p(1)^{n-1}=n p \\
\mathrm{~V}(X) &=g_{X}^{\prime \prime}(1)+g_{X}^{\prime}(1)\left(1-g_{X}^{\prime}(1)\right)=n(n-1) p^{2}(p+1-p)^{n-2}+n p(1-n p) \\
&=n p\left((n-1) p(1)^{n-2}+(1-n p)\right)=n p(n p-p+1-n p)=n p(1-p) .
\end{aligned}
$$
\conclusion{On retrouve bien l'espérance et la variance de la loi binomiale.}
Cette méthode efficace peut bien sûr être utilisée pour calculer les moments d'autres lois de probabilité finies.

\end{enumerate}
\end{enumerate}





\end{correction}

\end{document}